{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1334d81e-ba04-4a88-9799-1e177fb694e3",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739b0de-98c6-4a2d-91ae-06dab23e6f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28075f33-3fe3-4de2-a586-d6740e3392c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils #Drawing helpers\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08a344-8594-4277-bfd3-bc7553209d6e",
   "metadata": {},
   "source": [
    "# 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3760c2-7fda-4dd3-b08c-e05c78f96c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model\n",
    "dir_model = \"../Model/xyz/\"\n",
    "\n",
    "# you can try different model\n",
    "# dir_model = \"../Model/xyz_hand/\"\n",
    "# dir_model = \"../Model/xy/\"\n",
    "# dir_model = \"../Model/xy_hand/\"\n",
    "\n",
    "loaded_model = tf.saved_model.load(dir_model)\n",
    "inferer = loaded_model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a414c0-e654-490f-944f-1963d979d1c9",
   "metadata": {},
   "source": [
    "# 2. Setup OpenCV and MediaPipe to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4be66-414b-4bd1-92b4-25c399f7ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_video_test = ('')\n",
    "cap = cv2.VideoCapture(dir_video_test)\n",
    "current_stage = ''\n",
    "\n",
    "#initiate holistic model\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    # stream the video\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # recolor feed\n",
    "        image = cv2.flip(frame, 1)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # make detection\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        # recolor image back to BGR for rendering\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "\n",
    "        # try to predict\n",
    "        try:\n",
    "            # model xyz\n",
    "            row = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten()\n",
    "            X = pd.DataFrame([row])\n",
    "            grip_class = np.argmax(inferer(inputs=X)['output_0'].numpy())\n",
    "            grip_prob = np.max(inferer(inputs=X)['output_0'].numpy())\n",
    "\n",
    "            # model xyz_hand\n",
    "            # row = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark[13:22]]).flatten()\n",
    "            # X = pd.DataFrame([row])\n",
    "            # grip_class = np.argmax(inferer(inputs=X)['output_0'].numpy())\n",
    "            # grip_prob = np.max(inferer(inputs=X)['output_0'].numpy())\n",
    "\n",
    "            # model xy\n",
    "            # row = np.array([[res.x, res.y] for res in results.pose_landmarks.landmark[]]).flatten()\n",
    "            # X = pd.DataFrame([row])\n",
    "            # grip_class = np.argmax(inferer(inputs=X)['output_0'].numpy())\n",
    "            # grip_prob = np.max(inferer(inputs=X)['output_0'].numpy())\n",
    "\n",
    "            # model xy_hand\n",
    "            # row = np.array([[res.x, res.y] for res in results.pose_landmarks.landmark[13:22]]).flatten()\n",
    "            # X = pd.DataFrame([row])\n",
    "            # grip_class = np.argmax(inferer(inputs=X)['output_0'].numpy())\n",
    "            # grip_prob = np.max(inferer(inputs=X)['output_0'].numpy())\n",
    "\n",
    "            print(grip_class, grip_prob)\n",
    "\n",
    "            if grip_class == 0 and grip_prob >= 0.9 :\n",
    "                current_stage = 'Good'\n",
    "            elif grip_class == 1 and grip_prob >= 0.9 :\n",
    "                current_stage = 'Narrow'\n",
    "            elif grip_class == 2 and grip_prob >= 0.9 :\n",
    "                current_stage = 'Wide'\n",
    "\n",
    "            # get status box\n",
    "            cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "\n",
    "            #Display class\n",
    "            cv2.putText(image, 'Class', (95, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, current_stage, (95, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "            #Display Prob\n",
    "            cv2.putText(image, 'PROB', (15, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(round(grip_prob, 2)), (15, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        # Stream vid resultq\n",
    "        cv2.imshow(\"Raw Cam Feed\", image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
